# Feature Engineering Course Syllabus

## Course Information

**Course Title:** Feature Engineering
**Program:** Data Science
**Prerequisites:** Basic data science knowledge
**Instructor:** Lea Villasante Núñez
**Term:** Spring
**Level:** Graduate
**Duration:** 13 weeks (including assessment)
**Total Hours:** Active learning hours: 39 hours
**Type of Course:** Core
**Credits:** 3 US credits
**Course Delivery:** Online asynchronous

## Course Description

This course guides students through the process of preparing and transforming raw data into useful inputs for machine learning models. It will introduce aspiring data scientists to practical and advanced techniques for feature engineering using Python. Students will learn to transform raw data into effective model inputs across structured, temporal, and unstructured domains, while understanding scalability and emerging AI applications importance.

## Course Learning Outcomes

Upon completion of the course, the students should be able to:

- **CLO1:** Explain key feature engineering concepts, terminology and techniques such as handling missing data, noise, and discuss their importance on feature quality and model outcomes.
- **CLO2:** Implement key feature engineering techniques, including categorical encoding, numerical transformations, and aggregations on structured and unstructured datasets.
- **CLO3:** Examine feature relationships and importance using feature selection and dimensionality reduction techniques to optimize model input.

## Assessment

The course assessment is divided into two categories:

**Core Assessments (Summative; 60%) – Mandatory**
- Mid-term: 30%
- Final: 30%

**Practice Activities (Formative; 40%) – Optional but Credit-Bearing**
- Weekly Knowledge Checks: 10%
- Weekly Learning Engagement: 30%

Note: Core assessments are compulsory for course completion. Practice activities are optional but contribute to the final grade.

## Weekly Modules

### Week 1: Introduction to Feature Engineering

**Overview:** Define feature engineering and its role in the machine learning lifecycle. Explain how feature quality influences model performance and differentiate between raw data, features, and engineered features.

**Weekly Learning Objectives:**
- **WLO1:** Define feature engineering and its role in the machine learning lifecycle. (CLO1)
- **WLO2:** Explain how feature quality influences model performance. (CLO1)
- **WLO3:** Differentiate between raw data, features, and engineered features. (CLO1)
- **WLO4:** Identify the relationship between feature engineering, data preprocessing, and modeling. (CLO1)

### Week 2: Feature Engineering Fundamentals - Understanding and Classifying Variables

**Overview:** Classify variables into categorical, numerical, ordinal, and time-based types. Describe data distributions and variable types, and apply exploratory analysis techniques.

**Weekly Learning Objectives:**
- **WLO1:** Classify variables into categorical, numerical, ordinal, and time-based and explain why variable classification matters for choosing transformations. (CLO1)
- **WLO2:** Describe data distributions and variable types. (CLO1)
- **WLO3:** Apply exploratory analysis techniques to understand feature properties. (CLO2)

### Week 3: Handling Missing, Incomplete and Noisy Data

**Overview:** Evaluate strategies for handling missing data including imputation, deletion, and indicator variables. Apply noise reduction techniques to structured datasets.

**Weekly Learning Objectives:**
- **WLO1:** Evaluate strategies for handling missing data (imputation, deletion, indicator variables). (CLO1)
- **WLO2:** Apply noise reduction techniques to structured datasets. (CLO2)

### Week 4: Encoding Categorical Features

**Overview:** Compare common encoding methods including one-hot, label, target, frequency, and embeddings. Choose appropriate encoding strategies and implement categorical feature encodings in Python.

**Weekly Learning Objectives:**
- **WLO1:** Compare common encoding methods (one-hot, label, target, frequency, embeddings). (CLO2)
- **WLO2:** Choose appropriate encoding strategies based on variable type and model family. (CLO2)
- **WLO3:** Implement categorical feature encodings in Python. (CLO2)
- **WLO4:** Evaluate encoding choices by measuring model performance impact. (CLO2)

### Week 5: Transforming Numerical Features

**Overview:** Explain the importance of scaling, normalization, and standardization. Apply transformation techniques including log, Box-Cox, polynomial, and binning methods.

**Weekly Learning Objectives:**
- **WLO1:** Explain the importance of scaling, normalization, and standardization. (CLO1)
- **WLO2:** Apply transformation techniques (log, Box-Cox, polynomial, binning). (CLO2)
- **WLO3:** Detect and handle outliers in numerical data. (CLO2)
- **WLO4:** Evaluate the effect of numerical transformations on feature distributions and models. (CLO2)

### Week 6: Feature Engineering for Structured Tabular Data

**Overview:** Combine categorical and numerical feature engineering techniques in tabular datasets. Engineer interaction features, ratios, and aggregated statistics.

**Weekly Learning Objectives:**
- **WLO1:** Combine categorical and numerical feature engineering techniques in tabular datasets. (CLO2)
- **WLO2:** Engineer interaction features, ratios, and aggregated statistics. (CLO2)
- **WLO3:** Implement domain-driven feature creation from structured data. (CLO2)
- **WLO4:** Assess engineered tabular features through model validation. (CLO3)

### Week 7: Summative Assessment

**Overview:** Mid-term assessment week covering material from Weeks 1-6.

### Week 8: Time and Date Features

**Overview:** Extract time-based features including day, month, weekday, seasonality, and lags. Apply rolling statistics and windowing for temporal data.

**Weekly Learning Objectives:**
- **WLO1:** Extract time-based features (day, month, weekday, seasonality, lags). (CLO2)
- **WLO2:** Apply rolling statistics and windowing for temporal data. (CLO2)
- **WLO3:** Engineer features that capture temporal patterns and trends. (CLO2)
- **WLO4:** Evaluate time-based feature contributions in predictive tasks. (CLO3)

### Week 9: Feature Engineering for Unstructured Data

**Overview:** Identify feature engineering techniques for text, images, and audio. Apply text preprocessing including tokenization, TF-IDF, and embeddings.

**Weekly Learning Objectives:**
- **WLO1:** Analyze feature engineering techniques for text, images, and audio. (CLO1)
- **WLO2:** Apply text preprocessing (tokenization, TF-IDF, embeddings). (CLO2)
- **WLO3:** Engineer basic image and signal features. (CLO2)
- **WLO4:** Evaluate the challenges of unstructured feature extraction versus structured data. (CLO3)

### Week 10: Feature Selection Techniques

**Overview:** Differentiate between filter, wrapper, and embedded selection methods. Apply feature importance, mutual information, and statistical tests.

**Weekly Learning Objectives:**
- **WLO1:** Differentiate between filter, wrapper, and embedded selection methods. (CLO3)
- **WLO2:** Apply feature importance, mutual information, and statistical tests. (CLO3)
- **WLO3:** Implement dimensionality reduction techniques (PCA, t-SNE, UMAP). (CLO3)
- **WLO4:** Evaluate trade-offs between interpretability, dimensionality, and model performance. (CLO3)

### Week 11: Scalable Feature Engineering Pipelines

**Overview:** Build reusable pipelines with scikit-learn, pandas, and PySpark. Automate preprocessing and feature engineering workflows.

**Weekly Learning Objectives:**
- **WLO1:** Build reusable pipelines with scikit-learn, pandas, and PySpark. (CLO2)
- **WLO2:** Automate preprocessing and feature engineering workflows. (CLO2)
- **WLO3:** Integrate feature stores and scalable ML platforms. (CLO2)
- **WLO4:** Evaluate pipeline scalability in real-world ML systems. (CLO3)

### Week 12: Feature Engineering for Generative and Agentic AI Systems

**Overview:** Explain the role of features in generative and agent-based AI models. Engineer prompt-based and embedding-driven features.

**Weekly Learning Objectives:**
- **WLO1:** Explain the role of features in generative and agent-based AI models. (CLO1)
- **WLO2:** Engineer prompt-based and embedding-driven features. (CLO2)
- **WLO3:** Apply feature engineering to reinforcement learning and LLM fine-tuning contexts. (CLO2)
- **WLO4:** Critically assess challenges of feature engineering in generative/agentic AI. (CLO3)

### Week 13: Summative Assessment

**Overview:** Final assessment week covering comprehensive course material.

## Required Reading Materials

### Week 1: Introduction to Feature Engineering
- Zheng, A., & Casari, A. (2018). Feature engineering for machine learning: principles and techniques for data scientists (First edition). O'Reilly Media. Chapter 1.
- Ozdemir, S. (2022). Feature engineering bootcamp ([First edition]). Manning Publications Co. Chapter 1.

### Week 2: Feature Engineering Fundamentals - Understanding and Classifying Variables
- Galli, S., & Molnar, C. (2024). Python feature engineering cookbook: a complete guide to crafting powerful features for your machine learning models (Third edition). Packt Publishing Ltd. Chapters 1-2.
- Zheng, A., & Casari, A. (2018). Feature engineering for machine learning: principles and techniques for data scientists (First edition). O'Reilly Media. Chapter 2.

### Week 3: Handling Missing, Incomplete and Noisy Data
- Galli, S., & Molnar, C. (2024). Python feature engineering cookbook: a complete guide to crafting powerful features for your machine learning models (Third edition). Packt Publishing Ltd. Chapters 3-4.
- Ozdemir, S. (2022). Feature engineering bootcamp ([First edition]). Manning Publications Co. Chapter 3.

### Week 4: Encoding Categorical Features
- Zheng, A., & Casari, A. (2018). Feature engineering for machine learning: principles and techniques for data scientists (First edition). O'Reilly Media. Chapter 5.
- Galli, S., & Molnar, C. (2024). Python feature engineering cookbook: a complete guide to crafting powerful features for your machine learning models (Third edition). Packt Publishing Ltd. Chapter 5.

### Week 5: Transforming Numerical Features
- Zheng, A., & Casari, A. (2018). Feature engineering for machine learning: principles and techniques for data scientists (First edition). O'Reilly Media. Chapter 4.
- Ozdemir, S. (2022). Feature engineering bootcamp ([First edition]). Manning Publications Co. Chapter 4.

### Week 6: Feature Engineering for Structured Tabular Data
- Galli, S., & Molnar, C. (2024). Python feature engineering cookbook: a complete guide to crafting powerful features for your machine learning models (Third edition). Packt Publishing Ltd. Chapters 6-7.
- Zheng, A., & Casari, A. (2018). Feature engineering for machine learning: principles and techniques for data scientists (First edition). O'Reilly Media. Chapter 6.

### Week 8: Time and Date Features
- Ozdemir, S. (2022). Feature engineering bootcamp ([First edition]). Manning Publications Co. Chapter 5.
- Galli, S., & Molnar, C. (2024). Python feature engineering cookbook: a complete guide to crafting powerful features for your machine learning models (Third edition). Packt Publishing Ltd. Chapter 8.

### Week 9: Feature Engineering for Unstructured Data
- Zheng, A., & Casari, A. (2018). Feature engineering for machine learning: principles and techniques for data scientists (First edition). O'Reilly Media. Chapters 7-8.
- Ozdemir, S. (2022). Feature engineering bootcamp ([First edition]). Manning Publications Co. Chapter 6.

### Week 10: Feature Selection Techniques
- Zheng, A., & Casari, A. (2018). Feature engineering for machine learning: principles and techniques for data scientists (First edition). O'Reilly Media. Chapter 9.
- Galli, S., & Molnar, C. (2024). Python feature engineering cookbook: a complete guide to crafting powerful features for your machine learning models (Third edition). Packt Publishing Ltd. Chapters 9-10.

### Week 11: Scalable Feature Engineering Pipelines
- Ozdemir, S. (2022). Feature engineering bootcamp ([First edition]). Manning Publications Co. Chapter 7.
- Galli, S., & Molnar, C. (2024). Python feature engineering cookbook: a complete guide to crafting powerful features for your machine learning models (Third edition). Packt Publishing Ltd. Chapter 11.

### Week 12: Feature Engineering for Generative and Agentic AI Systems
- Zheng, A., & Casari, A. (2018). Feature engineering for machine learning: principles and techniques for data scientists (First edition). O'Reilly Media. Chapter 10.
- Claydon, S. Feature Engineering with Python: Unlocking the Power of Data for Machine Learning. Chapter 8.

## Assessments

### Midterm Assessment: Feature Engineering in Practice
**Format:** Group Project (2–4 students)
**Assessment Type:** Practical Assignment + GitHub Submission
**CLOs Covered:** CLO1, CLO2

**Project Overview:** Work in small groups to explore a real-world dataset, conduct exploratory data analysis, and apply feature engineering techniques that improve the predictive quality of a machine learning model using the Titanic Survival Dataset.

### Final Assessment: From Raw Data to Actionable Features
**Format:** Group Project
**CLOs Covered:** CLO1, CLO2, CLO3

**Project Overview:** End-to-end feature engineering pipeline using the NYC 311 Service Request dataset. Design features to predict whether a complaint will be closed within 24 hours, including advanced techniques and critical evaluation of impact on predictive models.